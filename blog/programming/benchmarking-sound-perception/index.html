<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="/blog/pico.min.css">
  <link rel="stylesheet" href="/blog/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">
  <script defer="" src="/blog/js/katex.min.js" integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>
  <script defer="" src="/blog/js/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">
  <link rel="stylesheet" href="/blog/dracula.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/go.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/fortran.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/cpp.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/julia.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/c.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/haskell.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/perl.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/rust.min.js"></script>
  <script type="text/javascript" src="https://unpkg.com/highlightjs-lean/dist/lean.min.js"></script>
  <script>
   hljs.highlightAll();
  </script>
 </head>
 <body>
  <main>
   <h1>
    Benchmarking my perception of sound
   </h1>
   <p>
    <strong>15 December 2024</strong>
   </p>
   <p>
    <em>Learning about Bayesian statistics and the Jeffreys
prior</em>
   </p>
   <hr>
   <br>
   <p>
    I’ve been learning about Bayesian statistics and computational
methods recently so I want to work on a few small projects to put into
practice what I have been learning.
   </p>
   <p>
    Today I decided to benchmark my perception of sound: I created a game
where I’m played a random tone and I have to respond with a number that
is as close as possible to the frequency that was played. I sample
frequencies uniformly at random between 131Hz and 495Hz.
   </p>
   <p>
    I wanted to do this experiment as I came up for two models for how
I’d perform on this game. If we let \(Y\) be the frequency I report and
\(X\) be the frequency that I actually heard, my first model is that I
will give the frequency that I heard added to some normally distributed
error term, that is
   </p>
   <p>
    \[Y_i = X_i + \epsilon_i \]
   </p>
   <p>
    Where \(\epsilon_i \sim \mathcal{N}(\mu, \sigma^2)\). If this is the
case, I’d expect \(\mu\) to be zero as I don’t expect to have a
consistent bias to guessing higher or lower than the actual
frequency.
   </p>
   <p>
    My second model is motivated by the fact that human sound perception
is inherently logarithmic and musical intervals are actually frequency
ratios. For example, playing C3 then E3 sounds the same as playing a C4
then E4: it’s just an octave higher however the difference between C3
and E3 is about 35Hz and the difference between C4 and E4 is about 70Hz.
And in fact, an octave difference is a doubling of the frequency not a
fixed difference in Hz. My second model hypothesises that the
differences between the <em>logarithms</em> of the frequencies or <a href="https://en.wikipedia.org/wiki/Cent_%28music%29">“cents”</a> is
normally distributed.
   </p>
   <p>
    \[ \log Y_i = \log X_i + \epsilon_i \]
   </p>
   <p>
    Where \(\epsilon_i\) is again a normally distributed error term.
   </p>
   <p>
    I decided to test these two models as I hypothesised that my absolute
error in frequency would become worse for higher tones which is a
consequence of the second model but not the first model. This came about
as earlier this week, I began teaching myself to report numerical
frequencies as opposed to the musical note names: I wanted to teach
myself to respond with “440 Hertz” as opposed to “A4” in response to
hearing a tone played at 440Hz.
   </p>
   <p>
    I quickly created a python script to collect this data. It looks like
this
   </p>
   <div class="sourceCode" id="cb1">
    <pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pysine</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>LOWEST <span class="op">=</span> <span class="dv">131</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>HIGHEST <span class="op">=</span> <span class="dv">494</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>should_continue <span class="op">=</span> <span class="va">True</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>played <span class="op">=</span> []</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>heard <span class="op">=</span> []</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>iteration <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> should_continue:</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        iteration <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        tone <span class="op">=</span> LOWEST <span class="op">+</span> random.random() <span class="op">*</span> (HIGHEST <span class="op">-</span> LOWEST)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        read <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> read <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>            pysine.sine(tone)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>            entered <span class="op">=</span> <span class="bu">input</span>(<span class="ss">f"</span><span class="sc">{</span>iteration<span class="sc">}</span><span class="ss">&gt;&gt; "</span>).lower().strip()</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> entered <span class="op">==</span> <span class="st">"q"</span>:</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>                should_continue <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> entered <span class="op">==</span> <span class="st">"r"</span>:</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                read <span class="op">=</span> <span class="bu">float</span>(entered)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span>:</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">"Unable to read number"</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Played </span><span class="sc">{</span>tone<span class="sc">}</span><span class="ss">, you heard </span><span class="sc">{</span>read<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        played.append(tone)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        heard.append(read)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">KeyboardInterrupt</span>:</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">EOFError</span>:</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"tone,heard"</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x, y <span class="kw">in</span> <span class="bu">zip</span>(played, heard):</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
   </div>
   <p>
    Here are the results from my first play through of the game where I
answered 20 questions
   </p>
   <p>
    <img src="/blog/images/perception.png">
   </p>
   <p>
    From a glance both of these models seem fairly sensible: my reported
frequency appears to closely track the frequency that I actually heard.
The error plot for my first game looks like this
   </p>
   <p>
    <img src="/blog/images/perception-error.png">
   </p>
   <p>
    It’s hard to get any insights from this by just analysing the data
visually, so I turn to statistics to compare how well these models
explain the data.
   </p>
   <p>
    The first thing I do is play another round of the game but this time
I listen to 50 tones instead of just 20. The sine waves were also pretty
boring to listen to so I synthesised my own instrument however I did a
quick runthrough of the game with the synthesiser I made and I noticed
that there was a clear upwards bias in the frequency that I reported. I
reverted back to using sine waves and noticed that this bias disappeared
which indicates that this bias was an artefact of how I wrote my
synthesiser. I added <a href="https://en.wikipedia.org/wiki/Harmonic">harmonics</a> but not <a href="https://en.wikipedia.org/wiki/Undertone_series">subharmonics</a>
to my synth so this may have caused me to perceive the notes from the
synthesiser as being higher than they actually were. That’s the
euphemistic way of explaining that <a href="https://en.wikipedia.org/wiki/Software_bug">I wrote a bad
synth</a>.
   </p>
   <p>
    After going back to using sine waves, the data I’m analysing looks
like this
   </p>
   <p>
    <img src="/blog/images/perception-two.png">
   </p>
   <p>
    The error looks like this
   </p>
   <p>
    <img src="/blog/images/perception-error-two.png">
   </p>
   <p>
    Now, the absolute error looks like this
   </p>
   <p>
    <img src="/blog/images/perception-abs-error-two.png">
   </p>
   <p>
    This final graph is important as it shows that the error term is
clearly <a href="https://en.wikipedia.org/wiki/Homoscedasticity_and_heteroscedasticity">heteroskedastic</a>
which means that the variance of the error term is not constant: the
error term has much larger variance for higher frequencies.
   </p>
   <p>
    This matters because the first model predicts a homoskedastic
resdiual term which does not match the data. My second model predicts
heteroskedasticity but also predicts that the error for log frequency is
homoskedastic. The plot for the absolute error between log frequencies
looks like this
   </p>
   <p>
    <img src="/blog/images/perception-abs-cents-error-two.png">
   </p>
   <p>
    Visually, this is homoskedastic which is really good for the second
model and is strong evidence that the second model better explains the
data. Now, let’s quantitatively examine these models using bayesian
statistics.
   </p>
   <p>
    Bayesian statistics centres itself around <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes’ rule</a>
which states that \(p(\theta | x) \propto p(x | \theta) \times p(\theta)
\) or that the likelihood of \(\theta\) after having observed \(x\) is
proportional to the prior likelihood of theta multiplied by the
probability of observing \(x\) with parameter \(\theta\).
   </p>
   <p>
    What does this mean? If we have a distribution representing our
beliefs about the value of \(\theta\), Bayes’ rule tells us how to
update our beliefs after observing new data. The distribution from
before observing the data is called our <a href="https://en.wikipedia.org/wiki/Prior_probability">“prior”</a> and
the updated distirbution after observing the data is called the <a href="https://en.wikipedia.org/wiki/Posterior_probability">“posterior”</a>.
   </p>
   <p>
    If we fix \(\mu = 0\) for both models then both models become single
paramter models as we have \(\epsilon_i \sim \mathcal{N}(0, \sigma^2)\).
What is my prior distribution for \(\sigma\)?
   </p>
   <p>
    For the sake of learning I’d like to use an uninformative prior:
specifically, the <a href="https://en.wikipedia.org/wiki/Jeffreys_prior">Jeffreys prior</a>,
named after <a href="https://en.wikipedia.org/wiki/Harold_Jeffreys">Harold
Jeffreys</a>.
   </p>
   <p>
    The Jeffreys prior gives us a prior distribution that is invariant
under montone transformations of the parameter. For example, if I took a
uniform distribution as my prior for \(\sigma^2\) between 0 and 1 then
the implied distribution of \(\sigma\) would also be between 0 and 1 but
it would <em>not</em> be uniform. We can contrast this to the Jeffreys
prior where the Jeffreys prior for \(\sigma^2\) aligns with the Jeffreys
prior for \(\sigma\).
   </p>
   <p>
    The Jeffrey’s prior is specified as proportional to the square root
of the determinant of the <a href="https://en.wikipedia.org/wiki/Fisher_information">Fisher
information matrix</a>.
   </p>
   <p>
    \[ p(\theta) \propto \sqrt{\operatorname{det} \mathcal{I}(\theta)}
\]
   </p>
   <p>
    Our normal distribution with mean 0 looks like
   </p>
   <p>
    \[ f(x ; \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}}
e^{-\frac{x^2}{2\sigma^2}} \]
   </p>
   <p>
    We have a single parameter model so we get
   </p>
   <p>
    \[ \begin{align*} p(\sigma) &amp;\propto \sqrt{\mathbb E \left[
\left. \left( \frac{\partial}{\partial \sigma} \log f(x;\sigma)
\right)^2 \right| \sigma \right]} \\ &amp;= \sqrt{\mathbb E \left[
\left( \frac{\partial}{\partial \sigma} \log
\frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{x^2}{2\sigma^2}} \right)^2
\right]} \\ &amp;= \sqrt{\mathbb E \left[ \left(
\frac{\partial}{\partial \sigma} \log e^{-\frac{x^2}{2\sigma^2}} - \log
\sqrt{2\pi\sigma^2} \right)^2 \right]} \\ &amp;= \sqrt{\mathbb E \left[
\left( \frac{\partial}{\partial \sigma} - \frac{x^2}{2\sigma^2} - \log
\sigma - \frac{1}{2} \log 2\pi \right)^2 \right]} \\ &amp;=
\sqrt{\mathbb E \left[ \left( \frac{\partial}{\partial \sigma}
-\frac{x^2}{2\sigma^2} - \log \sigma \right)^2 \right]} \\ &amp;=
\sqrt{\mathbb E \left[\left( \frac{x^2}{\sigma^{3}} - \frac{1}{\sigma}
\right)^2 \right]} \\ &amp;= \sqrt{\frac{1}{\sigma^2} \mathbb E
\left[\left( \frac{x^2}{\sigma^2} - 1 \right)^2 \right] } \\
&amp;\propto \sqrt{\frac{1}{\sigma^2} } \\ &amp;= \frac{1}{\sigma}
\end{align*} \]
   </p>
   <p>
    Unfortunately, this is an <a href="https://en.wikipedia.org/wiki/Prior_probability#Improper_priors">improper
prior</a> and the integral across the support is not finite and does not
form a true <a href="https://en.wikipedia.org/wiki/Probability_distribution">probability
distribution</a>. I’m too scared to use an improper prior after reading
about how they can lead to nonsense inference results. Analysing whether
or not they’re appropriate to use <a href="https://www.jstor.org/stable/2242007">appears to be very
complicated</a> so I’ll stay away from improper priors for a few
years.
   </p>
   <p>
    Fortunately, I can create my own uninformative prior. I want to feign
ignorance about both the variance and the standard deviation so I’d like
a prior that ensures me transformational invariance between \(\sigma\)
and \(\sigma^2\) I can get this with any pair of distributions
\(f_{\sigma}\) and \(f_{\sigma^2}\) that satisfy
   </p>
   <p>
    \[ \begin{align*} f_{\sigma}(x) &amp;= \frac{dx^2}{dx}
f_{\sigma^2}(x) \\ &amp;= 2xf_{\sigma^2}(x) \end{align*} \]
   </p>
   <p>
    So we now have
   </p>
   <p>
    \[ \begin{align*} \int_a^{\infty} f_{\sigma^2}(x) dx &amp;=
\int_a^\infty f_{\sigma}(x) dx \\ \int_a^{\infty} f_{\sigma^2}(x) dx
&amp;= \int_a^\infty 2xf_{\sigma^2}(x) dx \\ \int_a^{\infty}
f_{\sigma^2}(x) \left( 1 - 2x \right) dx &amp;= 0 \end{align*} \]
   </p>
   <p>
    Integrating this by parts we get
   </p>
   <p>
    \[ \begin{align*} \int_a^{\infty} f_{\sigma^2}(x) \left( 1 - 2x
\right) dx &amp;= 0 \\ -f_{\sigma^2}(0) + 2 \int_a^\infty
F_{\sigma^2}(x) dx &amp;= 0 \\ 2 \int_a^\infty F_{\sigma^2}(x) dx &amp;=
f_{\sigma^2}(a) \\ 2 \mathbb E\left[\sigma^2\right] dx &amp;=
f_{\sigma^2}(a) \end{align*} \]
   </p>
   <p>
    Where \(F_{\sigma^2}\) denotes the CDF for \(f_{\sigma^2}\) and \(a\)
lower bounds the variance in this distribution. Unfortunately, I do not
want to solve this functional equation so I’ll just use the Jeffreys
prior.
   </p>
   <p>
    Using the Jeffreys prior for the linear model gives me the following
posterior distribution
   </p>
   <p>
    <img src="/blog/images/posterior-sigma.png">
   </p>
   <p>
    The Jeffreys prior for the log-linear model gives me the following
posterior distribution
   </p>
   <p>
    <img src="/blog/images/posterior-sigma-log.png">
   </p>
   <p>
    After taking the MLE for each of these models I can find a point
estimate for the <a href="https://en.wikipedia.org/wiki/Bayes_factor">Bayes factor</a> for
the two models. The Bayes factor allows me to quantify how much better
one model explains the data than another.
   </p>
   <p>
    My code for calculating the likelihoods for each of the models looks
like this
   </p>
   <div class="sourceCode" id="cb2">
    <pre class="sourceCode R"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>likelihood_linear <span class="ot">&lt;-</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(df<span class="sc">$</span>heard <span class="sc">-</span> df<span class="sc">$</span>tone, <span class="at">mean=</span><span class="dv">0</span>, <span class="at">sd=</span>sigma_linear))</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>likelihood_log <span class="ot">&lt;-</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="fu">log</span>(df<span class="sc">$</span>heard) <span class="sc">-</span> <span class="fu">log</span>(df<span class="sc">$</span>tone), <span class="at">mean=</span><span class="dv">0</span>, <span class="at">sd=</span>sigma_log))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>likelihood_log <span class="sc">/</span> likelihood_linear</span></code></pre>
   </div>
   <p>
    The likelihood for the the first model is about \(10^{-68}\) whereas
the likelihood for the second model comes out to be around \(10^{59}\).
This gives us a ratio of about \(10^{125}\) and numerically integrating
over the posterior distributions to approximate the true Bayes factor
gives me about the same result which is a <a href="https://en.wikipedia.org/wiki/Bayes_factor#Interpretation">decisive</a>
victory for the log-linear model.
   </p>
   <p>
    I learned a lot through this project and I really enjoyed surveying
Bayesian statistics while doing background reading and was super fun all
around.
   </p>
  </main>
 </body>
</html>
